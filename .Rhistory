rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 50)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 900)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 900)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
precision <- TP / (TP + FP)
F1 <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
recall
precision <- TP / (TP + FP)
precision
F1 <- 2 * precision * recall / (precision + recall)
F1
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
knitr::opts_chunk$set(echo = TRUE)
library(ezids)
library(ggplot2)
library(treemapify)
library(dplyr)
<<<<<<< Updated upstream
library(gridExtra)
fire <- read.csv("data_2018_clean.csv")
str(fire)
head(fire)
xkablesummary(fire, title = "Fire Statistics Summary")
table(fire$NWCG_CAUSE_CLASSIFICATION)
ggplot(fire, aes(x = NWCG_CAUSE_CLASSIFICATION)) +
geom_bar(col = "black", fill = "white", alpha = 0.7) +
labs(title = "Fire Cause Classification",
x = "Cause Classification",
y = "Number of Incidents")
general_cause_counts <- table(fire$NWCG_GENERAL_CAUSE)
general_cause_counts <- sort(general_cause_counts, decreasing = TRUE)
general_cause_counts
fire_cause_summary <- as.data.frame(table(fire$NWCG_GENERAL_CAUSE))
colnames(fire_cause_summary) <- c("Cause", "Count")
ggplot(fire_cause_summary,
aes(area = Count, fill = Cause, label = paste(Cause, "\n", Count))) +
geom_treemap() +
geom_treemap_text(colour = "white", place = "centre", grow = TRUE) +
labs(title = "Fire Incident Causes",
subtitle = "Proportion of Each General Cause across All Regions") +
theme(legend.position = "none")
state_counts <- table(fire$STATE)
state_counts
barplot(state_counts,
main = "Fire Incidents by State",
xlab = "State",
ylab = "Number of Incidents",
col = "red")
state_stats <- data.frame(
STATE = c("DC", "MD", "VA"),
AREA_SQ_MI = c(68, 12407, 42775),
POP_2018 = c(702455, 6035802, 8517685)
)
state_counts_df <- as.data.frame(table(fire$STATE))
colnames(state_counts_df) <- c("STATE", "FIRE_COUNT")
state_summary <- merge(state_counts_df, state_stats, by = "STATE")
state_summary$FIRE_PER_100K <- (state_summary$FIRE_COUNT / state_summary$POP_2018) * 100000
state_summary$FIRE_PER_SQMI <- state_summary$FIRE_COUNT / state_summary$AREA_SQ_MI
state_summary
ggplot(state_summary, aes(x = STATE, y = FIRE_PER_100K, fill = STATE)) +
geom_bar(stat = "identity", color = "black") +
labs(title = "Fire Incidents per 100,000 Population (2018)",
y = "Incidents per 100,000 people") +
theme_minimal(base_size = 14)
ggplot(state_summary, aes(x = STATE, y = FIRE_PER_SQMI, fill = STATE)) +
geom_bar(stat = "identity", color = "black") +
labs(title = "Fire Density per Square Mile (2018)",
y = "Incidents per sq. mile") +
theme_minimal(base_size = 14)
urban_counties <- c("Washington, D.C.",
"Montgomery County", "Prince George's County", "Baltimore City",
"Anne Arundel County", "Howard County",
"Fairfax County", "Arlington County", "Virginia Beach City",
"Chesterfield County", "Henrico County", "Loudoun County")
rural_counties <- c("Garrett County", "Allegany County", "Washington County",
"Caroline County", "Somerset County", "Dorchester County",
"Bath County", "Highland County", "Scott County",
"Lee County", "Tazewell County", "Wise County")
fire$AREA_TYPE <- ifelse(fire$FIPS_NAME %in% urban_counties, "Urban", "Rural")
table(fire$AREA_TYPE)
ggplot(fire, aes(x = AREA_TYPE, y = FIRE_SIZE, fill = AREA_TYPE)) +
geom_boxplot(alpha = 0.7, color = "black") +
labs(title = "Fire Size Distribution by Area Type",
x = "Area Type", y = "Fire Size") +
theme_minimal(base_size = 12)
table(fire$AREA_TYPE, fire$NWCG_GENERAL_CAUSE)
ggplot(data = fire, aes(x = NWCG_GENERAL_CAUSE, fill = AREA_TYPE)) +
geom_bar(position = "dodge") +
labs(title = "Distribution of Fire Causes by Area Type",
x = "General Cause", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
chisq.test(table(fire$AREA_TYPE, fire$NWCG_GENERAL_CAUSE))
qqnorm(fire$FIRE_SIZE)
qqline(fire$FIRE_SIZE)
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
# 1. Clean target variable BEFORE splitting
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
table(data_clean$Wildfire)
# 2. Split into train (2018) and test (2019)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
recall
precision <- TP / (TP + FP)
precision
F1 <- 2 * precision * recall / (precision + recall)
F1
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(e1071)
# 1. Ensure target is factor (must be done BEFORE training)
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
# 2. Train-test split for 2018–2019
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
# 3. Train SVM (Radial kernel is default)
svm_model <- svm(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
kernel = "radial",
probability = TRUE
)
# 4. Predictions
svm_pred <- predict(svm_model, test2019)
# 5. Confusion matrix
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm
# 6. Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)
svm_accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
=======
library(tidymodels)
library(readr)
data_1 = read.csv('/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleands.csv')
View(data_1)
View(data_1)
data_1$FIRE_YEAR
name(data_1$FIRE_YEAR)
unique(data_1$FIRE_YEAR)
data = read.csv('/Users/jeongwonyoo/Documents/GitHub/introds-project2/data_clean.csv')
View(data)
View(data_1)
unique(data$FIRE_YEAR)
View(data)
View(data_1)
View(data_clean)
View(data_1)
View(data)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleaned.csv'
data = read.csv(path)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleands.csv'
data = read.csv(path)
set.seed(43)
data_split <- initial_split(
data,
prop = 0.7,
strata = NWCG_CAUSE_CLASSIFICATION
)
library(dplyr)
library(tidymodels)
set.seed(43)
data_split = initial_split(
data,
prop = 0.7,
strata = NWCG_CAUSE_CLASSIFICATION
)
train_data = training(data_split)
test_data  = testing(data_split)
data$NWCG_CAUSE_CLASSIFICATION <- factor(
data$NWCG_CAUSE_CLASSIFICATION,
levels = c("Natural", "Human"))
str(data)
unique(data$Month)
data$Month = trimws(datra$Month)
data$Month = trimws(data$Month)
unique(data$Month)
data$Month[data$Month == 'febuary'] = 'February'
unique(data$Month)
data$Month[data$Month == 'february'] = 'February'
unique(data$Month)
write.csv(data, "data_2018_clean.csv", row.names = FALSE)
>>>>>>> Stashed changes
path = ''/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data 2018-2019.csv''
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv'
data = read.csv(path)
library(readr)
library(dplyr)
library(tidymodels)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv'
data = read.csv(path)
file.exists("/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv")
file.info("/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv")$size
readLines("/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv", n = 5)
readLines("/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data_2018_2019.csv", n = 20)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data 2018-2019.csv'
data = read.csv(path)
str(data)
View(data)
data$Wildfire = factor(
data$Wildfire,
levels = c('Yes', 'No'))
data$Wildfire = factor(
data$Wildfire,
levels = c('No', 'Yes'))
is.na(data)
sum(is.na(data))
train_2018 = subset(data, Year == 2018)
test_2019 = subset(datam, Year == 2019)
train_2018 = subset(data, Year == 2018)
test_2019 = subset(data, Year == 2019)
logit_model = glm(Wildfire ~.,
data = train_2018,
family = binomial)
summary(logit_model)
train_2018 = subset(data, Year == 2018, select = -Year)
test_2019 = subset(data, Year == 2019, select= -Year)
logit_model = glm(Wildfire ~.,
data = train_2018,
family = binomial)
summary(logit_model)
test_2019$prob_yes <- predict(
logit_model,
newdata = test_2019,
type = "response"
)
test_2019$pred <- ifelse(test_2019$prob_yes >= 0.5, "Yes", "No")
test_2019$pred <- factor(test_2019$pred, levels = c("No","Yes"))
cm <- table(Predicted = test_2019$pred,
Actual    = test_2019$Wildfire)
cm
TP <- cm["Yes", "Yes"]
FP <- cm["Yes", "No"]
FN <- cm["No",  "Yes"]
precision <- TP / (TP + FP)
recall    <- TP / (TP + FN)
precision
recall
test_2019$pred <- ifelse(test_2019$prob_yes >= 0.1, "Yes", "No")
cm <- table(Predicted = test_2019$pred,
Actual    = test_2019$Wildfire)
cm
test_2019$pred <- ifelse(test_2019$prob_yes >= 0.2, "Yes", "No")
cm <- table(Predicted = test_2019$pred,
Actual    = test_2019$Wildfire)
cm
test_2019$pred <- ifelse(test_2019$prob_yes >= 0.3, "Yes", "No")
cm <- table(Predicted = test_2019$pred,
Actual    = test_2019$Wildfire)
cm
install.packages('rpart')
install.packages('rpart.plot')
library(readr)
library(dplyr)
library(tidymodels)
library(rpart)
library(rpart.plot)
# data
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire_Incidence_Data 2018-2019.csv'
data = read.csv(path)
data$Wildfire = factor(
data$Wildfire,
levels = c('No', 'Yes'))
train_2018 = subset(data, Year == 2018, select = -Year)
test_2019 = subset(data, Year == 2019, select= -Year)
tree_model <- rpart(
Wildfire ~ .,
data   = train_2018,
method = "class",
control = rpart.control(
minsplit = 50,
cp       = 0.001
)
)
printcp(tree_model)
rpart.plot(tree_model)
test_2019$tree_pred_class <- predict(
tree_model,
newdata = test_2019,
type = "class"
)
tree_prob <- predict(
tree_model,
newdata = test_2019,
type = "prob"
)
test_2019$tree_prob_yes <- tree_prob[, "Yes"]
cm_tree <- table(
Predicted = test_2019$tree_pred_class,
Actual    = test_2019$Wildfire
)
cm_tree
TP <- cm_tree["Yes", "Yes"]
FP <- cm_tree["Yes", "No"]
FN <- cm_tree["No",  "Yes"]
TN <- cm_tree["No",  "No"]
accuracy  <- (TP + TN) / sum(cm_tree)
precision <- TP / (TP + FP)
recall    <- TP / (TP + FN)
accuracy
precision
recall
View(tree_prob)
install.package('DMwR')
install.packages('DMwR')
install.packages('smotefamily')
library(smotefamily)
train_no_year <- train_2018[, setdiff(names(train_2018), "YEAR")]
smote_result <- SMOTE(train_no_year[, -which(names(train_no_year)=="Wildfire")],
train_no_year$Wildfire,
K = 5)
train_smote <- cbind(smote_result$data, Wildfire = smote_result$class)
X <- train_2018[, setdiff(names(train_2018), c("Wildfire", "YEAR"))]
y <- train_2018$Wildfire
table(y)
smote_out <- SMOTE(X, y, K = 5)
train_smote <- smote_out$data
colnames(train_smote)[ncol(train_smote)] <- "Wildfire"
train_smote$Wildfire <- factor(train_smote$Wildfire, levels = c("No", "Yes"))
tree_smote <- rpart(
Wildfire ~ .,
data = train_smote,
method = "class",
control = rpart.control(minsplit = 50, cp = 0.001)
)
test_2019$tree_pred_smote <- predict(
tree_smote,
newdata = test_2019,
type = "class"
)
cm_smote <- table(
Predicted = test_2019$tree_pred_smote,
Actual    = test_2019$Wildfire
)
cm_smote
# cp 테이블 출력
printcp(tree_smote)
# xerror가 최소가 되는 cp 선택
best_cp <- tree_smote$cptable[which.min(tree_smote$cptable[, "xerror"]), "CP"]
best_cp
# 가지치기된 트리 만들기
tree_pruned <- prune(tree_smote, cp = best_cp)
# 트리 그림 다시 보고 싶으면
rpart.plot(tree_pruned)
# 클래스 예측
test_2019$tree_pred_pruned <- predict(
tree_pruned,
newdata = test_2019,
type = "class"
)
# 혼동행렬
cm_pruned <- table(
Predicted = test_2019$tree_pred_pruned,
Actual    = test_2019$Wildfire
)
cm_pruned
TP <- cm_pruned["Yes", "Yes"]
FP <- cm_pruned["Yes", "No"]
FN <- cm_pruned["No",  "Yes"]
TN <- cm_pruned["No",  "No"]
accuracy_pruned  <- (TP + TN) / sum(cm_pruned)
precision_pruned <- TP / (TP + FP)
recall_pruned    <- TP / (TP + FN)
accuracy_pruned
precision_pruned
recall_pruned
