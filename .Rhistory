# Accuracy
rf_accuracy <- sum(diag(cm)) / sum(cm)
rf_accuracy
# Load data
data_clean <- read.csv("your_file.csv")
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
df$Year <- as.numeric(df$Year)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(df$Year)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
nrow(train2018)
nrow(test2019)
climate_vars <- c("pr","rmax","rmin","sph","srad","tmmn","tmmx",
"vs","bi","fm100","fm1000","erc","etr","pet","vpd")
cor_matrix <- cor(train2018[, climate_vars], use = "pairwise.complete.obs")
round(cor_matrix, 2)
num_vars <- train[, c("latitude", "longitude", "pr", "rmax", "rmin", "sph",
"srad", "tmmn", "tmmx", "vs", "bi", "fm100",
"fm1000", "erc", "etr", "pet", "vpd")]
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
nrow(train2018)
nrow(test2019)
names(data_clean)
library(corrplot)
numeric_vars <- train2018[, sapply(train2018, is.numeric)]
corr <- cor(numeric_vars, method = "pearson")
corrplot(corr,type = "upper",method = "number",title = "Correlations (2018 Climate Variables)")
library(corrplot)
num_vars <- train2018 %>%
select(-Wildfire) %>%           # remove the target
mutate(across(everything(), as.numeric))   # force numeric
corr_pearson <- cor(num_vars, use = "pairwise.complete.obs")
corrplot(corr_pearson,
type = "upper",
method = "number",
tl.col="black",
title = "Pearson Correlation (Climate Variables)")
library(corrplot)
numeric_vars <- train2018[, sapply(train2018, is.numeric)]
corr <- cor(numeric_vars, method = "pearson")
corrplot(corr,type = "upper",method = "number",title = "Correlations (2018 Climate Variables)")
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(corrplot)
library(e1071)
library(randomForest)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
set.seed(123)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE
)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
nrow(train2018)
nrow(test2019)
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
set.seed(123)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE
)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
set.seed(123)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE
)
# Load data
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
data_clean$Year <- as.numeric(data_clean$Year)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
# 1. Clean target variable BEFORE splitting
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
table(data_clean$Wildfire)
# 2. Split into train (2018) and test (2019)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(e1071)
# 1. Ensure target is factor (must be done BEFORE training)
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
# 2. Train-test split for 2018–2019
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
# 3. Train SVM (Radial kernel is default)
svm_model <- svm(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
kernel = "radial",
probability = TRUE
)
# 4. Predictions
svm_pred <- predict(svm_model, test2019)
# 5. Confusion matrix
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm
# 6. Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)
svm_accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 20)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 300)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 50)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 900)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 900)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
precision <- TP / (TP + FP)
F1 <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
recall
precision <- TP / (TP + FP)
precision
F1 <- 2 * precision * recall / (precision + recall)
F1
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
knitr::opts_chunk$set(echo = TRUE)
library(ezids)
library(ggplot2)
library(treemapify)
library(dplyr)
<<<<<<< Updated upstream
library(gridExtra)
fire <- read.csv("data_2018_clean.csv")
str(fire)
head(fire)
xkablesummary(fire, title = "Fire Statistics Summary")
table(fire$NWCG_CAUSE_CLASSIFICATION)
ggplot(fire, aes(x = NWCG_CAUSE_CLASSIFICATION)) +
geom_bar(col = "black", fill = "white", alpha = 0.7) +
labs(title = "Fire Cause Classification",
x = "Cause Classification",
y = "Number of Incidents")
general_cause_counts <- table(fire$NWCG_GENERAL_CAUSE)
general_cause_counts <- sort(general_cause_counts, decreasing = TRUE)
general_cause_counts
fire_cause_summary <- as.data.frame(table(fire$NWCG_GENERAL_CAUSE))
colnames(fire_cause_summary) <- c("Cause", "Count")
ggplot(fire_cause_summary,
aes(area = Count, fill = Cause, label = paste(Cause, "\n", Count))) +
geom_treemap() +
geom_treemap_text(colour = "white", place = "centre", grow = TRUE) +
labs(title = "Fire Incident Causes",
subtitle = "Proportion of Each General Cause across All Regions") +
theme(legend.position = "none")
state_counts <- table(fire$STATE)
state_counts
barplot(state_counts,
main = "Fire Incidents by State",
xlab = "State",
ylab = "Number of Incidents",
col = "red")
state_stats <- data.frame(
STATE = c("DC", "MD", "VA"),
AREA_SQ_MI = c(68, 12407, 42775),
POP_2018 = c(702455, 6035802, 8517685)
)
state_counts_df <- as.data.frame(table(fire$STATE))
colnames(state_counts_df) <- c("STATE", "FIRE_COUNT")
state_summary <- merge(state_counts_df, state_stats, by = "STATE")
state_summary$FIRE_PER_100K <- (state_summary$FIRE_COUNT / state_summary$POP_2018) * 100000
state_summary$FIRE_PER_SQMI <- state_summary$FIRE_COUNT / state_summary$AREA_SQ_MI
state_summary
ggplot(state_summary, aes(x = STATE, y = FIRE_PER_100K, fill = STATE)) +
geom_bar(stat = "identity", color = "black") +
labs(title = "Fire Incidents per 100,000 Population (2018)",
y = "Incidents per 100,000 people") +
theme_minimal(base_size = 14)
ggplot(state_summary, aes(x = STATE, y = FIRE_PER_SQMI, fill = STATE)) +
geom_bar(stat = "identity", color = "black") +
labs(title = "Fire Density per Square Mile (2018)",
y = "Incidents per sq. mile") +
theme_minimal(base_size = 14)
urban_counties <- c("Washington, D.C.",
"Montgomery County", "Prince George's County", "Baltimore City",
"Anne Arundel County", "Howard County",
"Fairfax County", "Arlington County", "Virginia Beach City",
"Chesterfield County", "Henrico County", "Loudoun County")
rural_counties <- c("Garrett County", "Allegany County", "Washington County",
"Caroline County", "Somerset County", "Dorchester County",
"Bath County", "Highland County", "Scott County",
"Lee County", "Tazewell County", "Wise County")
fire$AREA_TYPE <- ifelse(fire$FIPS_NAME %in% urban_counties, "Urban", "Rural")
table(fire$AREA_TYPE)
ggplot(fire, aes(x = AREA_TYPE, y = FIRE_SIZE, fill = AREA_TYPE)) +
geom_boxplot(alpha = 0.7, color = "black") +
labs(title = "Fire Size Distribution by Area Type",
x = "Area Type", y = "Fire Size") +
theme_minimal(base_size = 12)
table(fire$AREA_TYPE, fire$NWCG_GENERAL_CAUSE)
ggplot(data = fire, aes(x = NWCG_GENERAL_CAUSE, fill = AREA_TYPE)) +
geom_bar(position = "dodge") +
labs(title = "Distribution of Fire Causes by Area Type",
x = "General Cause", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
chisq.test(table(fire$AREA_TYPE, fire$NWCG_GENERAL_CAUSE))
qqnorm(fire$FIRE_SIZE)
qqline(fire$FIRE_SIZE)
data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")
# 1. Clean target variable BEFORE splitting
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
table(data_clean$Wildfire)
# 2. Split into train (2018) and test (2019)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)
nrow(train2018)
nrow(test2019)
print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")
library(corrplot)
num_vars <- train2018[, c("pr","rmax","rmin","sph","srad",
"tmmn","tmmx","vs","bi",
"fm100","fm1000","erc","etr","pet","vpd")]
corr_mat <- cor(num_vars, method = "pearson")
corrplot(corr_mat, method="number", type="upper",
tl.col="black", title="Correlations (Climate Variables)")
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
TP <- cm["Yes","Yes"]
FN <- cm["No","Yes"]
FP <- cm["Yes","No"]
recall <- TP / (TP + FN)
recall
precision <- TP / (TP + FP)
precision
F1 <- 2 * precision * recall / (precision + recall)
F1
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
library(e1071)
# 1. Ensure target is factor (must be done BEFORE training)
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))
# 2. Train-test split for 2018–2019
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)
# 3. Train SVM (Radial kernel is default)
svm_model <- svm(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
kernel = "radial",
probability = TRUE
)
# 4. Predictions
svm_pred <- predict(svm_model, test2019)
# 5. Confusion matrix
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm
# 6. Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)
svm_accuracy
library(randomForest)
rf_model <- randomForest(
Wildfire ~ latitude + longitude + pr + rmax + rmin + sph + srad +
tmmn + tmmx + vs + bi + fm100 + fm1000 + erc + etr + pet + vpd,
data = train2018,
ntree = 500,
importance = TRUE,
classwt = c("No" = 1, "Yes" = 2500)
)
# 4. Predictions
rf_pred <- predict(rf_model, test2019)
# 5. Confusion Matrix
cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
cm
# 6. Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
accuracy
=======
library(tidymodels)
library(readr)
data_1 = read.csv('/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleands.csv')
View(data_1)
View(data_1)
data_1$FIRE_YEAR
name(data_1$FIRE_YEAR)
unique(data_1$FIRE_YEAR)
data = read.csv('/Users/jeongwonyoo/Documents/GitHub/introds-project2/data_clean.csv')
View(data)
View(data_1)
unique(data$FIRE_YEAR)
View(data)
View(data_1)
View(data_clean)
View(data_1)
View(data)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleaned.csv'
data = read.csv(path)
path = '/Users/jeongwonyoo/Documents/GitHub/introds-project2/Fire incidences DC_VA_MD_cleands.csv'
data = read.csv(path)
set.seed(43)
data_split <- initial_split(
data,
prop = 0.7,
strata = NWCG_CAUSE_CLASSIFICATION
)
library(dplyr)
library(tidymodels)
set.seed(43)
data_split = initial_split(
data,
prop = 0.7,
strata = NWCG_CAUSE_CLASSIFICATION
)
train_data = training(data_split)
test_data  = testing(data_split)
data$NWCG_CAUSE_CLASSIFICATION <- factor(
data$NWCG_CAUSE_CLASSIFICATION,
levels = c("Natural", "Human"))
str(data)
unique(data$Month)
data$Month = trimws(datra$Month)
data$Month = trimws(data$Month)
unique(data$Month)
data$Month[data$Month == 'febuary'] = 'February'
unique(data$Month)
data$Month[data$Month == 'february'] = 'February'
unique(data$Month)
write.csv(data, "data_2018_clean.csv", row.names = FALSE)
>>>>>>> Stashed changes
