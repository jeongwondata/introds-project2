---
title: "Project2"
output: html_document
date: "2025-11-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(ezids)
library(ggplot2)
library(treemapify)
library(dplyr)
library(gridExtra)
library(e1071)
library(smotefamily)
library(randomForest)
library(e1071)
library(ROCR)
library(corrplot)
```

```{r}

data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")

# 1. Clean target variable BEFORE splitting
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))

table(data_clean$Wildfire)

# 2. Split into train (2018) and test (2019)
train2018 <- subset(data_clean, Year == 2018, select = -Year)
test2019  <- subset(data_clean, Year == 2019, select = -Year)

data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)

nrow(train2018)
nrow(test2019)

print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")

table(train2018$Wildfire)

colSums(is.na(train2018[train2018$Wildfire == "Yes", ]))


```
```{r}

num_vars <- train2018[, c("pr","rmax","rmin","sph","srad","tmmn")]

corr_mat <- cor(num_vars, method = "pearson")

corrplot(corr_mat, method = "number", type="upper",
         tl.col="black", title="Correlation Matrix (Climate Variables)")



```
```{r}

yes_cases <- train2018 %>% filter(Wildfire == "Yes")
no_cases  <- train2018 %>% filter(Wildfire == "No")

set.seed(123)
upsampled_yes <- yes_cases %>% sample_n(nrow(no_cases), replace = TRUE)

train_balanced <- bind_rows(no_cases, upsampled_yes)

table(train2018$Wildfire)
table(train_balanced$Wildfire)   # now balanced




```

random forest

```{r}


rf_model <- randomForest(
  Wildfire ~ .,
  data = train_balanced,
  ntree = 500,
  importance = TRUE
)

rf_pred <- predict(rf_model, test2019)
rf_cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
rf_cm


rf_accuracy <- sum(diag(rf_cm)) / sum(rf_cm)
rf_accuracy

TP <- rf_cm["Yes","Yes"]
FN <- rf_cm["No","Yes"]
FP <- rf_cm["Yes","No"]

rf_precision <- TP / (TP + FP)
rf_recall    <- TP / (TP + FN)
rf_f1        <- 2 * (rf_precision * rf_recall) / (rf_precision + rf_recall)

c(precision = rf_precision, recall = rf_recall, F1 = rf_f1)

rf_prob <- predict(rf_model, test2019, type = "prob")[,"Yes"]

pred <- prediction(rf_prob, test2019$Wildfire)
perf <- performance(pred, "tpr", "fpr")

plot(perf, col="blue", lwd=2, main="Random Forest ROC Curve")
abline(0,1,lty=2,col="gray")

# Numeric importance values
importance(rf_model)

# Plot graph
varImpPlot(rf_model, main = "Random Forest Feature Importance")

```

```{r}
# Convert RF importance to a data frame
imp <- importance(rf_model)

imp_df <- data.frame(
  Feature = rownames(imp),
  Importance = imp[, "MeanDecreaseGini"]   # Change if you prefer MeanDecreaseAccuracy
)

# Plot all 20 features (no top_n needed)
imp_df %>%
  ggplot(aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col(fill = "lightblue") +
  coord_flip() +
  labs(
    title = "Feature Importance for Wildfire Prediction",
    x = "Feature",
    y = "Mean Decrease in Gini (Variable Importance)"
  ) +
  theme_minimal(base_size = 13)

```

Random Forest + SMOTE
```{r}
# 2) Random Forest on SMOTE balanced data
set.seed(123)

rf_model <- randomForest(
  Wildfire ~ .,
  data = train_balanced,
  ntree = 500,
  importance = TRUE
)

# Predictions
rf_pred <- predict(rf_model, test2019)
rf_cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
rf_cm

# Metrics
rf_accuracy <- sum(diag(rf_cm)) / sum(rf_cm)

TP <- rf_cm["Yes", "Yes"]
FN <- rf_cm["No",  "Yes"]
FP <- rf_cm["Yes", "No"]

rf_precision <- TP / (TP + FP)
rf_recall    <- TP / (TP + FN)
rf_f1        <- 2 * (rf_precision * rf_recall) / (rf_precision + rf_recall)

c(accuracy = rf_accuracy,
  precision = rf_precision,
  recall    = rf_recall,
  F1        = rf_f1)

# ROC curve
rf_prob <- predict(rf_model, test2019, type = "prob")[, "Yes"]

pred <- prediction(rf_prob, test2019$Wildfire)
perf <- performance(pred, "tpr", "fpr")

plot(perf, col = "blue", lwd = 2, main = "Random Forest ROC Curve (SMOTE)")
abline(0, 1, lty = 2, col = "gray")

# Variable importance
importance(rf_model)
varImpPlot(rf_model, main = "Random Forest Feature Importance (SMOTE)")

imp <- importance(rf_model)

imp_df <- data.frame(
  Feature    = rownames(imp),
  Importance = imp[, "MeanDecreaseGini"]
)

imp_df %>%
  ggplot(aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Feature Importance for Wildfire Prediction (RF + SMOTE)",
    x = "Feature",
    y = "Mean Decrease in Gini"
  ) +
  theme_minimal(base_size = 13)
```


 svm
```{r}


train2018$Year <- NULL
test2019$Year <- NULL


svm_model <- svm(
  Wildfire ~ .,
  data = train2018,
  kernel = "radial",
  probability = TRUE,
  scale = TRUE,
  class.weights = c("No" = 1, "Yes" = 50)
)


# 4. Predictions
svm_pred <- predict(svm_model, test2019)

# 5. Confusion matrix
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm

# 6. Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)
svm_accuracy

# Precision, Recall, F1
TP <- svm_cm["Yes", "Yes"]
FN <- svm_cm["No", "Yes"]
FP <- svm_cm["Yes", "No"]

svm_precision <- TP / (TP + FP)
svm_recall    <- TP / (TP + FN)
svm_f1        <- 2 * (svm_precision * svm_recall) / (svm_precision + svm_recall)

c(
  precision = svm_precision,
  recall    = svm_recall,
  F1        = svm_f1
)

# ---- ROC & AUC ----

# Probability predictions
svm_prob <- attr(
  predict(svm_model, test2019, probability = TRUE),
  "probabilities"
)[, "Yes"]

# ROCR performance objects
pred_svm <- prediction(svm_prob, test2019$Wildfire)
perf_svm <- performance(pred_svm, "tpr", "fpr")

# Plot ROC curve
plot(perf_svm, col = "red", lwd = 2, main = "SVM ROC Curve")
abline(0, 1, lty = 2, col = "gray")

# AUC
svm_auc <- performance(pred_svm, "auc")@y.values[[1]]
svm_auc


```

SVM + SMOTE

```{r}
# SVM on SMOTE balanced data
svm_model <- svm(
  Wildfire ~ .,
  data = train_balanced,   # SMOTE data
  kernel = "radial",
  probability = TRUE,
  scale = TRUE
)

# Predictions
svm_pred <- predict(svm_model, test2019)
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm

# Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)

# Metrics
TP_svm <- svm_cm["Yes", "Yes"]
FN_svm <- svm_cm["No",  "Yes"]
FP_svm <- svm_cm["Yes", "No"]

svm_precision <- TP_svm / (TP_svm + FP_svm)
svm_recall    <- TP_svm / (TP_svm + FN_svm)
svm_f1        <- 2 * (svm_precision * svm_recall) / (svm_precision + svm_recall)

c(
  accuracy  = svm_accuracy,
  precision = svm_precision,
  recall    = svm_recall,
  F1        = svm_f1
)
```