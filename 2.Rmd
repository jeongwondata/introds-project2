---
title: "Project2"
output: html_document
date: "2025-11-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(ezids)
library(ggplot2)
library(treemapify)
library(dplyr)
library(gridExtra)

```

```{r}
library(ggplot2)
library(dplyr)
library(randomForest)
library(e1071)
library(ROCR)
library(corrplot)


data_clean <- read.csv("Fire_Incidence_Data 2018-2019.csv")

# 1. Clean target variable BEFORE splitting
data_clean$Wildfire <- trimws(data_clean$Wildfire)
data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No","Yes"))

table(data_clean$Wildfire)

# 2. Split into train (2018) and test (2019)
train2018 <- subset(data_clean, Year == 2018)
test2019  <- subset(data_clean, Year == 2019)

data_clean$Wildfire <- factor(data_clean$Wildfire, levels = c("No", "Yes"))
str(data_clean$Wildfire)
table(data_clean$Wildfire)

nrow(train2018)
nrow(test2019)

print(colnames(data_clean))
table(data_clean$Wildfire, useNA = "ifany")

table(train2018$Wildfire)

colSums(is.na(train2018[train2018$Wildfire == "Yes", ]))


```
```{r}

num_vars <- train2018[, c("pr","rmax","rmin","sph","srad","tmmn")]

corr_mat <- cor(num_vars, method = "pearson")

corrplot(corr_mat, method = "number", type="upper",
         tl.col="black", title="Correlation Matrix (Climate Variables)")



```
```{r}

yes_cases <- train2018 %>% filter(Wildfire == "Yes")
no_cases  <- train2018 %>% filter(Wildfire == "No")

set.seed(123)
upsampled_yes <- yes_cases %>% sample_n(nrow(no_cases), replace = TRUE)

train_balanced <- bind_rows(no_cases, upsampled_yes)

table(train2018$Wildfire)
table(train_balanced$Wildfire)   # now balanced




```

random forest

```{r}


rf_model <- randomForest(
  Wildfire ~ .,
  data = train_balanced,
  ntree = 500,
  importance = TRUE
)

rf_pred <- predict(rf_model, test2019)
rf_cm <- table(Predicted = rf_pred, Actual = test2019$Wildfire)
rf_cm


rf_accuracy <- sum(diag(rf_cm)) / sum(rf_cm)
rf_accuracy

TP <- rf_cm["Yes","Yes"]
FN <- rf_cm["No","Yes"]
FP <- rf_cm["Yes","No"]

rf_precision <- TP / (TP + FP)
rf_recall    <- TP / (TP + FN)
rf_f1        <- 2 * (rf_precision * rf_recall) / (rf_precision + rf_recall)

c(precision = rf_precision, recall = rf_recall, F1 = rf_f1)

rf_prob <- predict(rf_model, test2019, type = "prob")[,"Yes"]

pred <- prediction(rf_prob, test2019$Wildfire)
perf <- performance(pred, "tpr", "fpr")

plot(perf, col="blue", lwd=2, main="Random Forest ROC Curve")
abline(0,1,lty=2,col="gray")

# Numeric importance values
importance(rf_model)

# Plot graph
varImpPlot(rf_model, main = "Random Forest Feature Importance")



```
```{r}

library(ggplot2)
library(dplyr)

# Convert RF importance to a data frame
imp <- importance(rf_model)

imp_df <- data.frame(
  Feature = rownames(imp),
  Importance = imp[, "MeanDecreaseGini"]   # Change if you prefer MeanDecreaseAccuracy
)

# Plot all 20 features (no top_n needed)
imp_df %>%
  ggplot(aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Feature Importance for Wildfire Prediction",
    x = "Feature",
    y = "Mean Decrease in Gini (Variable Importance)"
  ) +
  theme_minimal(base_size = 13)





```



 svm
```{r}


train2018$Year <- NULL
test2019$Year <- NULL


svm_model <- svm(
  Wildfire ~ .,
  data = train2018,
  kernel = "radial",
  probability = TRUE,
  scale = TRUE,
  class.weights = c("No" = 1, "Yes" = 50)
)


# 4. Predictions
svm_pred <- predict(svm_model, test2019)

# 5. Confusion matrix
svm_cm <- table(Predicted = svm_pred, Actual = test2019$Wildfire)
svm_cm

# 6. Accuracy
svm_accuracy <- sum(diag(svm_cm)) / sum(svm_cm)
svm_accuracy



```